{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tqdm import tqdm_notebook\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(taken, dob):\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "    \n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, dataset):\n",
    "    \n",
    "    meta = loadmat(os.path.join(data_dir, \"{}.mat\".format(dataset)))\n",
    "    \n",
    "    full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
    "    \n",
    "    dob = meta[dataset][0, 0][\"dob\"][0]\n",
    "    \n",
    "    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]\n",
    "    \n",
    "    name = meta[dataset][0, 0][\"name\"][0]\n",
    "    \n",
    "    age = np.array([calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))])\n",
    "    \n",
    "    images = []\n",
    "    for img_path in tqdm_notebook(full_path):\n",
    "        images.append(img_path[0])\n",
    "    \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, image_paths, image_shape):\n",
    "    \n",
    "    images = None\n",
    "    num_images = len(image_paths)\n",
    "    \n",
    "    for i, image_path in tqdm_notebook(enumerate(image_paths), total=num_images, leave=False):\n",
    "    \n",
    "        try:\n",
    "            # Load image\n",
    "            loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n",
    "            \n",
    "            # Convert PIL image to numpy ndarray\n",
    "            loaded_image = image.img_to_array(loaded_image)\n",
    "\n",
    "            # Add another dimension (Add batch dimension)\n",
    "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
    "            \n",
    "            if images is None:\n",
    "                images = loaded_image\n",
    "            else:\n",
    "                images = np.concatenate([images, loaded_image], axis=0)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", i, e)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = load_images(\"data/wiki_crop\")\n",
    "images, ages = load_data(\"data/wiki_crop\", \"wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -1\n",
    "images = images[:n]\n",
    "ages = ages[:n]\n",
    "print(images.shape)\n",
    "print(ages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = image.ImageDataGenerator(rescale=1. / 255)\n",
    "image_shape = (64, 64, 3)\n",
    "\n",
    "start = time.time()\n",
    "loaded_images = load_images(\"data/wiki_crop\", images, (image_shape[0], image_shape[1]))\n",
    "loaded_images = data_generator.standardize(loaded_images)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"wiki_preprocesed.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=loaded_images, compression=\"gzip\", compression_opts=9)\n",
    "    f.create_dataset(\"ages\", data=ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with h5py.File('wiki_preprocesed.hdf5', 'r') as f:\n",
    "    n_ages = np.array(f.get('ages'))\n",
    "    n_images = np.array(f.get('images'))\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ages.shape\n",
    "n_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(n_images[62323])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_chunk_generator(images, chunksize):\n",
    "    for i in range(0, images.shape[0], chunksize):\n",
    "        yield images[i:i + chunksize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = image.ImageDataGenerator(rescale=1. / 255)\n",
    "image_shape = (64, 64, 3)\n",
    "#images = load_images(\"data/wiki_crop\")\n",
    "images, ages = load_data(\"data/imdb_crop\", \"imdb\")\n",
    "num_imgs = images.shape[0]\n",
    "img_pr_process = num_imgs // 400\n",
    "\n",
    "chunk_generator = image_chunk_generator(images[num_imgs//2:], img_pr_process)\n",
    "#chunk_generator = image_chunk_generator(images[num_imgs//2:], img_pr_process)\n",
    "\n",
    "finnished_images = []\n",
    "for image_chunk in tqdm_notebook(chunk_generator, total = 201, desc=\"Image chunks\"):\n",
    "    loaded_images = load_images(\"data/imdb_crop\", image_chunk, (image_shape[0], image_shape[1]))\n",
    "    finnished_images.append(data_generator.standardize(loaded_images))\n",
    "\n",
    "loaded_images = np.concatenate(finnished_images)\n",
    "\n",
    "with h5py.File(\"imdb_preprocesed_2.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=loaded_images, compression=\"gzip\", compression_opts=9)\n",
    "    f.create_dataset(\"ages\", data=ages[num_imgs//2:])   \n",
    "\n",
    "print(\"done!\")\n",
    "    \n",
    "#for image_chunk in tqdm_notebook(chunk_generator2, total = 201, desc=\"Image chunks part 2\"):\n",
    "    #loaded_images = load_images(\"data/imdb_crop\", image_chunk, (image_shape[0], image_shape[1]))\n",
    "    #finnished_images.append(data_generator.standardize(loaded_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate(finnished_images)\n",
    "print(images.shape)\n",
    "print(ages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"imdb_preprocesed.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"images\", data=loaded_images, compression=\"gzip\", compression_opts=9)\n",
    "    f.create_dataset(\"ages\", data=ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with h5py.File('imdb_preprocesed_1.hdf5', 'r') as f:\n",
    "    n_ages = np.array(f.get('ages'))\n",
    "    n_images = np.array(f.get('images'))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_ages.shape)\n",
    "print(n_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
